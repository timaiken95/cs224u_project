{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timaiken/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from mittens import GloVe\n",
    "from mittens import Mittens\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import csv\n",
    "import re\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json('data.json')\n",
    "num_reviews, review_length = data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_token = '<UNK>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {}\n",
    "for r in range(num_reviews):\n",
    "    for w in range(review_length):\n",
    "        \n",
    "        currWordStruct = data[w][r]\n",
    "        if currWordStruct == None:\n",
    "            break\n",
    "        \n",
    "        currWord = currWordStruct[0]\n",
    "        \n",
    "        if currWord in vocab:\n",
    "            vocab[currWord] += 1\n",
    "        else:\n",
    "            vocab[currWord] = 1\n",
    "\n",
    "sort = sorted(vocab.items(), key=operator.itemgetter(1), reverse=True)[:4999]\n",
    "top_5k = {}\n",
    "counter = 0\n",
    "for word, _ in sort:\n",
    "    top_5k[word] = counter\n",
    "    counter += 1\n",
    "\n",
    "top_5k[unknown_token] = counter\n",
    "\n",
    "np.save('5k_vocab_dict.npy', top_5k) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_dict = {}\n",
    "for r in range(num_reviews):\n",
    "    for w in range(review_length):\n",
    "        \n",
    "        currWordStruct = data[w][r]\n",
    "        if not currWordStruct:\n",
    "            continue\n",
    "            \n",
    "        currWord = currWordStruct[0]\n",
    "\n",
    "        if currWord not in top_5k:\n",
    "            currWord = unknown_token\n",
    "\n",
    "        for other_w in range(-5, 6):\n",
    "\n",
    "            if ((w + other_w) < 0) or ((w + other_w) >= review_length) or (other_w == 0):\n",
    "                continue\n",
    "\n",
    "            otherWordStruct = data[w + other_w][r]\n",
    "            \n",
    "            if not otherWordStruct:\n",
    "                continue\n",
    "            \n",
    "            otherWord = otherWordStruct[0]\n",
    "            \n",
    "            if otherWord not in top_5k:\n",
    "                otherWord = unknown_token\n",
    "            \n",
    "            dist_weight = 1. / abs(other_w)\n",
    "\n",
    "            if other_w < 0:\n",
    "                if (otherWord, currWord) in co_dict:\n",
    "                    co_dict[(otherWord, currWord)] += dist_weight\n",
    "                else:\n",
    "                    co_dict[(otherWord, currWord)] = dist_weight\n",
    "\n",
    "            else:\n",
    "                if (currWord, otherWord) in co_dict:\n",
    "                    co_dict[(currWord, otherWord)] += dist_weight\n",
    "                else:\n",
    "                    co_dict[(currWord, otherWord)] = dist_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_matrix = np.zeros((5000, 5000))\n",
    "for word1, word2 in co_dict.keys():\n",
    "    co_matrix[top_5k[word1], top_5k[word2]] = co_dict[(word1, word2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glove2dict(glove_filename):\n",
    "    with open(glove_filename) as f:\n",
    "        reader = csv.reader(f, delimiter=' ', quoting=csv.QUOTE_NONE)\n",
    "        embed = {line[0]: np.array(list(map(float, line[1:])))\n",
    "                for line in reader}\n",
    "    return embed\n",
    "\n",
    "original_embeddings = glove2dict(\"glove.6B.300d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 500: loss: 159.19223022460938"
     ]
    }
   ],
   "source": [
    "vocab_array = vocab.keys()\n",
    "mittens_model = Mittens(n=300, max_iter=500)\n",
    "new_embeddings = mittens_model.fit(co_matrix, vocab = top_5k.keys(), initial_embedding_dict = original_embeddings)\n",
    "\n",
    "np.save('GloVe_codeswitch_5k.npy', new_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original word: have\n",
      "Related word:  having\n",
      "Related word:  had\n",
      "Related word:  been\n",
      "Related word:  say\n",
      "Related word:  already\n",
      "Related word:  come\n",
      "Related word:  both\n",
      "Related word:  should\n",
      "Related word:  yet\n",
      "[555 113 190 181 335  33 226 877 300 814]\n"
     ]
    }
   ],
   "source": [
    "embeddings = np.load('GloVe_codeswitch_5k.npy')\n",
    "vocab = np.load(\"5k_vocab_dict.npy\").item()\n",
    "inv_vocab = {v: k for k, v in vocab.items()}\n",
    "\n",
    "word = 'have' # pero, entonces, porque, don't, have\n",
    "\n",
    "idx = vocab[word]\n",
    "encoding = embeddings[idx,:]\n",
    "\n",
    "dists = np.sum(np.square(embeddings - encoding), axis=1)\n",
    "\n",
    "most_related = np.argpartition(dists, 10)[:10]\n",
    "\n",
    "print(\"Original word:\", word)\n",
    "for val in most_related:\n",
    "    if val == idx: continue\n",
    "    print(\"Related word: \", inv_vocab[val])\n",
    "\n",
    "print(most_related)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
